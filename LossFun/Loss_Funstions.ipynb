{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb5bc30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from LossFun.pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806a81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a437c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad2cb805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_flat(tensor):\n",
    "    return torch.mean(tensor, dim=list(range(1, len(tensor.shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c842c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_ssim(x, y, types = 'ssim'):\n",
    "    if types == 'ssim':\n",
    "        module = SSIM(data_range=1, size_average=False, channel=3)\n",
    "    else:\n",
    "        module = MS_SSIM(data_range=1, size_average=False, channel=3)\n",
    "        \n",
    "    return 1 - module(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26cbbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.rand(10, 3, 256, 256)\n",
    "y_test = torch.rand(10, 3, 256, 256)\n",
    "test = torch.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b85f544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_test = ms_ssim(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2db246b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9948)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_flat(z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d17096db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5764592e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3431)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_flat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab5ba649",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = MS_SSIM(data_range=1, size_average=False, channel=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9849696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "z_test = module(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0b3d0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91812627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Sample ground truth and predicted images\n",
    "ground_truth = torch.rand(1, 3, 256, 256)  # Example: 256x256 RGB image\n",
    "predicted_image = torch.rand(1, 3, 256, 256)\n",
    "\n",
    "# Mean Squared Error (MSE) Loss\n",
    "mse_loss = nn.MSELoss()\n",
    "loss_mse = mse_loss(predicted_image, ground_truth)\n",
    "\n",
    "# Mean Absolute Error (MAE) Loss\n",
    "mae_loss = nn.L1Loss()\n",
    "loss_mae = mae_loss(predicted_image, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df372676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5930a291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\env22\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\env22\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\Admin/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 528M/528M [00:05<00:00, 105MB/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m loss_perceptual \u001b[38;5;241m=\u001b[39m perceptual_loss(vgg16(predicted_image), vgg16(ground_truth))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Adversarial Loss (GAN Loss)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Assuming you have a discriminator and generator defined\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m fake_output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m(predicted_image)\n\u001b[0;32m     25\u001b[0m real_output \u001b[38;5;241m=\u001b[39m discriminator(ground_truth)\n\u001b[0;32m     26\u001b[0m loss_gan \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Perceptual Loss (VGG Loss)\n",
    "import torchvision.models as models\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "perceptual_loss = nn.MSELoss()\n",
    "loss_perceptual = perceptual_loss(vgg16(predicted_image), vgg16(ground_truth))\n",
    "\n",
    "# Adversarial Loss (GAN Loss)\n",
    "# Assuming you have a discriminator and generator defined\n",
    "fake_output = generator(predicted_image)\n",
    "real_output = discriminator(ground_truth)\n",
    "loss_gan = nn.BCELoss()\n",
    "loss_adversarial = loss_gan(fake_output, torch.ones_like(fake_output)) + loss_gan(real_output, torch.zeros_like(real_output))\n",
    "\n",
    "# Structural Similarity Index (SSIM) Loss\n",
    "import torch_ssim\n",
    "ssim_loss = torch_ssim.SSIM()\n",
    "loss_ssim = 1 - ssim_loss(predicted_image, ground_truth)\n",
    "\n",
    "# Dice Coefficient Loss\n",
    "# Assuming you have binary masks for segmentation\n",
    "def dice_coefficient(predicted, target):\n",
    "    intersection = torch.sum(predicted * target)\n",
    "    union = torch.sum(predicted) + torch.sum(target)\n",
    "    dice = (2 * intersection) / (union + 1e-5)\n",
    "    return 1 - dice\n",
    "\n",
    "loss_dice = dice_coefficient(predicted_mask, ground_truth_mask)\n",
    "\n",
    "# Cross-Entropy Loss\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "loss_ce = ce_loss(predicted_segmentation, ground_truth_segmentation)\n",
    "\n",
    "# Binary Cross-Entropy (BCE) Loss\n",
    "bce_loss = nn.BCELoss()\n",
    "loss_bce = bce_loss(predicted_binary_mask, ground_truth_binary_mask)\n",
    "\n",
    "# Kullback-Leibler Divergence (KL Divergence) Loss\n",
    "kl_loss = nn.KLDivLoss()\n",
    "loss_kl = kl_loss(torch.log(predicted_distribution), ground_truth_distribution)\n",
    "\n",
    "# Weighted Loss\n",
    "weights = torch.rand(1, 3, 256, 256)  # Define custom weights as needed\n",
    "weighted_mse_loss = nn.MSELoss(weight=weights)\n",
    "loss_weighted = weighted_mse_loss(predicted_image, ground_truth)\n",
    "\n",
    "# Custom Loss Function\n",
    "# Define your custom loss function as needed\n",
    "\n",
    "# Print the losses\n",
    "print(\"MSE Loss:\", loss_mse.item())\n",
    "print(\"MAE Loss:\", loss_mae.item())\n",
    "print(\"Perceptual Loss (VGG Loss):\", loss_perceptual.item())\n",
    "print(\"Adversarial Loss (GAN Loss):\", loss_adversarial.item())\n",
    "print(\"SSIM Loss:\", loss_ssim.item())\n",
    "print(\"Dice Coefficient Loss:\", loss_dice.item())\n",
    "print(\"Cross-Entropy Loss:\", loss_ce.item())\n",
    "print(\"Binary Cross-Entropy (BCE) Loss:\", loss_bce.item())\n",
    "print(\"KL Divergence Loss:\", loss_kl.item())\n",
    "print(\"Weighted Loss:\", loss_weighted.item())\n",
    "# Custom Loss: Compute and print custom loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c103138e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
