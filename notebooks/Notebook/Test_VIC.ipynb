{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f69b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LossFun import VIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862d9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fdfa069",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dim = 224\n",
    "local_crops_number = 2\n",
    "warmup_teacher_temp = 0.014\n",
    "teacher_temp = 0.04\n",
    "warmup_teacher_temp_epochs = 30\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e968ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============ preparing loss ... ============\n",
    "# dino_loss = VIC.DINOLoss(\n",
    "#     out_dim,\n",
    "#     local_crops_number + 2,  # total number of crops = 2 global crops + local_crops_number\n",
    "#     warmup_teacher_temp,\n",
    "#     teacher_temp,\n",
    "#     warmup_teacher_temp_epochs,\n",
    "#     epochs,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa05d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.rand(10, 224)\n",
    "# y = torch.rand(2, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bafdd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = dino_loss(x, y, epoch = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be709158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec84690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from types import SimpleNamespace\n",
    "\n",
    "# # Example dictionary\n",
    "# my_dict = {\n",
    "#     'name': 'Alice',\n",
    "#     'age': 30,\n",
    "#     'city': 'New York'\n",
    "# }\n",
    "\n",
    "# # Convert dictionary to SimpleNamespace\n",
    "# namespace = SimpleNamespace(**my_dict)\n",
    "\n",
    "# # Accessing attributes\n",
    "# print(namespace.name)  # Output: Alice\n",
    "# print(namespace.age)   # Output: 30\n",
    "# print(namespace.city)  # Output: New York\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c2d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # Example input tensor with shape (96, 3, 96, 96)\n",
    "# input_tensor = torch.randn(96, 3, 96, 96, requires_grad=True)\n",
    "\n",
    "# # Desired output size\n",
    "# output_size = (224, 224)\n",
    "\n",
    "# # Upsample the input tensor\n",
    "# upsampled_tensor = F.interpolate(input_tensor, size=output_size, mode='bilinear', align_corners=False)\n",
    "\n",
    "# # Define a simple loss function (mean of the tensor)\n",
    "# loss = upsampled_tensor.mean()\n",
    "\n",
    "# # Backpropagate the loss\n",
    "# loss.backward()\n",
    "\n",
    "# # Check if the gradients are not None\n",
    "# print(input_tensor.grad is not None)  # Should print True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "252d0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from helpers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21ee87c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention mode is math\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from TUVW import UViT\n",
    "from UModels.DiT import DiT_Anomaly\n",
    "from GaussianDiffusion import GaussianDiffusionModel, get_beta_schedule\n",
    "from torchvision import transforms as pth_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46a3ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = UViT(img_size = 224, patch_size=16, in_chans=3, embed_dim = 768,\n",
    "             depth=12, num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None, norm_layer=nn.LayerNorm, \n",
    "             mlp_time_embed=False, num_classes=None,\n",
    "             use_checkpoint=False, conv=True, skip=True)\n",
    "model = DiT_Anomaly(\n",
    "    input_size=256,\n",
    "    num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c81d0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = utils.MultiCropWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6564d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"model/diff-params-ARGS=73/params-final.pt\"\n",
    "model_path = \"saving_dir/Brain_MRI/UViT/checkpoint.pth\"\n",
    "model_path = r\"C:\\Users\\Admin\\Documents\\Anomaly Detection\\AnoDDPM\\model\\diff-params-ARGS=200\\params-final.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "305ea0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594a44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1b0cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23103e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(wts['ema'])\n",
    "# multi_model.load_state_dict(wts['teacher'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9bfbf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiT(\n",
       "  (x_embedder): PatchEmbed(\n",
       "    (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (t_embedder): TimestepEmbedder(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (y_embedder): LabelEmbedder(\n",
       "    (embedding_table): Embedding(3, 768)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x DiTBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='tanh')\n",
       "        (drop1): Dropout(p=0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (adaLN_modulation): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=768, out_features=4608, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): FinalLayer(\n",
       "    (norm_final): LayerNorm((768,), eps=1e-06, elementwise_affine=False)\n",
       "    (linear): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (adaLN_modulation): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas = get_beta_schedule(1000, 'cosine')        \n",
    "diffusion = GaussianDiffusionModel(\n",
    "    256,\n",
    "    betas, \n",
    "    args= args\n",
    ")       \n",
    "\n",
    "model.eval()\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a076e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"DATASETS/brainMRI/train/good/No22.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c15fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(image_path):\n",
    "    with open(image_path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        img = img.convert('L')\n",
    "else:\n",
    "    print(f\"Provided image path {args.image_path} is non valid.\")\n",
    "    sys.exit(1)\n",
    "transform = pth_transforms.Compose([\n",
    "    pth_transforms.Resize((256, 256)),\n",
    "    pth_transforms.ToTensor(),\n",
    "#     pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "img = transform(img).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2fa8acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = torch.tensor([0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19497e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fec3314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_embed\n",
      "x_embedder.proj.weight\n",
      "x_embedder.proj.bias\n",
      "t_embedder.mlp.0.weight\n",
      "t_embedder.mlp.0.bias\n",
      "t_embedder.mlp.2.weight\n",
      "t_embedder.mlp.2.bias\n",
      "y_embedder.embedding_table.weight\n",
      "blocks.0.attn.qkv.weight\n",
      "blocks.0.attn.qkv.bias\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.0.attn.proj.bias\n",
      "blocks.0.mlp.fc1.weight\n",
      "blocks.0.mlp.fc1.bias\n",
      "blocks.0.mlp.fc2.weight\n",
      "blocks.0.mlp.fc2.bias\n",
      "blocks.0.adaLN_modulation.1.weight\n",
      "blocks.0.adaLN_modulation.1.bias\n",
      "blocks.1.attn.qkv.weight\n",
      "blocks.1.attn.qkv.bias\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.1.mlp.fc1.weight\n",
      "blocks.1.mlp.fc1.bias\n",
      "blocks.1.mlp.fc2.weight\n",
      "blocks.1.mlp.fc2.bias\n",
      "blocks.1.adaLN_modulation.1.weight\n",
      "blocks.1.adaLN_modulation.1.bias\n",
      "blocks.2.attn.qkv.weight\n",
      "blocks.2.attn.qkv.bias\n",
      "blocks.2.attn.proj.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.2.mlp.fc1.weight\n",
      "blocks.2.mlp.fc1.bias\n",
      "blocks.2.mlp.fc2.weight\n",
      "blocks.2.mlp.fc2.bias\n",
      "blocks.2.adaLN_modulation.1.weight\n",
      "blocks.2.adaLN_modulation.1.bias\n",
      "blocks.3.attn.qkv.weight\n",
      "blocks.3.attn.qkv.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.3.mlp.fc1.weight\n",
      "blocks.3.mlp.fc1.bias\n",
      "blocks.3.mlp.fc2.weight\n",
      "blocks.3.mlp.fc2.bias\n",
      "blocks.3.adaLN_modulation.1.weight\n",
      "blocks.3.adaLN_modulation.1.bias\n",
      "blocks.4.attn.qkv.weight\n",
      "blocks.4.attn.qkv.bias\n",
      "blocks.4.attn.proj.weight\n",
      "blocks.4.attn.proj.bias\n",
      "blocks.4.mlp.fc1.weight\n",
      "blocks.4.mlp.fc1.bias\n",
      "blocks.4.mlp.fc2.weight\n",
      "blocks.4.mlp.fc2.bias\n",
      "blocks.4.adaLN_modulation.1.weight\n",
      "blocks.4.adaLN_modulation.1.bias\n",
      "blocks.5.attn.qkv.weight\n",
      "blocks.5.attn.qkv.bias\n",
      "blocks.5.attn.proj.weight\n",
      "blocks.5.attn.proj.bias\n",
      "blocks.5.mlp.fc1.weight\n",
      "blocks.5.mlp.fc1.bias\n",
      "blocks.5.mlp.fc2.weight\n",
      "blocks.5.mlp.fc2.bias\n",
      "blocks.5.adaLN_modulation.1.weight\n",
      "blocks.5.adaLN_modulation.1.bias\n",
      "blocks.6.attn.qkv.weight\n",
      "blocks.6.attn.qkv.bias\n",
      "blocks.6.attn.proj.weight\n",
      "blocks.6.attn.proj.bias\n",
      "blocks.6.mlp.fc1.weight\n",
      "blocks.6.mlp.fc1.bias\n",
      "blocks.6.mlp.fc2.weight\n",
      "blocks.6.mlp.fc2.bias\n",
      "blocks.6.adaLN_modulation.1.weight\n",
      "blocks.6.adaLN_modulation.1.bias\n",
      "blocks.7.attn.qkv.weight\n",
      "blocks.7.attn.qkv.bias\n",
      "blocks.7.attn.proj.weight\n",
      "blocks.7.attn.proj.bias\n",
      "blocks.7.mlp.fc1.weight\n",
      "blocks.7.mlp.fc1.bias\n",
      "blocks.7.mlp.fc2.weight\n",
      "blocks.7.mlp.fc2.bias\n",
      "blocks.7.adaLN_modulation.1.weight\n",
      "blocks.7.adaLN_modulation.1.bias\n",
      "blocks.8.attn.qkv.weight\n",
      "blocks.8.attn.qkv.bias\n",
      "blocks.8.attn.proj.weight\n",
      "blocks.8.attn.proj.bias\n",
      "blocks.8.mlp.fc1.weight\n",
      "blocks.8.mlp.fc1.bias\n",
      "blocks.8.mlp.fc2.weight\n",
      "blocks.8.mlp.fc2.bias\n",
      "blocks.8.adaLN_modulation.1.weight\n",
      "blocks.8.adaLN_modulation.1.bias\n",
      "blocks.9.attn.qkv.weight\n",
      "blocks.9.attn.qkv.bias\n",
      "blocks.9.attn.proj.weight\n",
      "blocks.9.attn.proj.bias\n",
      "blocks.9.mlp.fc1.weight\n",
      "blocks.9.mlp.fc1.bias\n",
      "blocks.9.mlp.fc2.weight\n",
      "blocks.9.mlp.fc2.bias\n",
      "blocks.9.adaLN_modulation.1.weight\n",
      "blocks.9.adaLN_modulation.1.bias\n",
      "blocks.10.attn.qkv.weight\n",
      "blocks.10.attn.qkv.bias\n",
      "blocks.10.attn.proj.weight\n",
      "blocks.10.attn.proj.bias\n",
      "blocks.10.mlp.fc1.weight\n",
      "blocks.10.mlp.fc1.bias\n",
      "blocks.10.mlp.fc2.weight\n",
      "blocks.10.mlp.fc2.bias\n",
      "blocks.10.adaLN_modulation.1.weight\n",
      "blocks.10.adaLN_modulation.1.bias\n",
      "blocks.11.attn.qkv.weight\n",
      "blocks.11.attn.qkv.bias\n",
      "blocks.11.attn.proj.weight\n",
      "blocks.11.attn.proj.bias\n",
      "blocks.11.mlp.fc1.weight\n",
      "blocks.11.mlp.fc1.bias\n",
      "blocks.11.mlp.fc2.weight\n",
      "blocks.11.mlp.fc2.bias\n",
      "blocks.11.adaLN_modulation.1.weight\n",
      "blocks.11.adaLN_modulation.1.bias\n",
      "final_layer.linear.weight\n",
      "final_layer.linear.bias\n",
      "final_layer.adaLN_modulation.1.weight\n",
      "final_layer.adaLN_modulation.1.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(n)\n",
    "#     if \"last_layer\" in n:\n",
    "#         p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7539a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f6b695d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msee_whole_sequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenoise_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgauss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m      9\u001b[0m     (\n\u001b[0;32m     10\u001b[0m         img\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[0;32m     11\u001b[0m         samples,                    \n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     13\u001b[0m ) \n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(gridify_output(outputs, \u001b[38;5;241m7\u001b[39m)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m], cmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\GaussianDiffusion.py:721\u001b[0m, in \u001b[0;36mGaussianDiffusionModel.forward_backward\u001b[1;34m(self, model, x, lab, see_whole_sequence, t_distance, denoise_fn)\u001b[0m\n\u001b[0;32m    717\u001b[0m             t_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([t], device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mrepeat(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    718\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    719\u001b[0m \u001b[38;5;66;03m#                 print(x.shape)\u001b[39;00m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;66;03m#                 print(t_batch.shape)\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m                 out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenoise_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m                 x \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    723\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m see_whole_sequence:\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\GaussianDiffusion.py:657\u001b[0m, in \u001b[0;36mGaussianDiffusionModel.sample_p\u001b[1;34m(self, model, x_t, t, lab, denoise_fn)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_p\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, x_t, t, lab, denoise_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgauss\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 657\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;66;03m# noise = torch.randn_like(x_t)\u001b[39;00m\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(denoise_fn) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\GaussianDiffusion.py:645\u001b[0m, in \u001b[0;36mGaussianDiffusionModel.p_mean_variance\u001b[1;34m(self, model, x_t, t, lab, estimate_noise, attn)\u001b[0m\n\u001b[0;32m    642\u001b[0m model_var \u001b[38;5;241m=\u001b[39m extract(model_var, t, x_t\u001b[38;5;241m.\u001b[39mshape, x_t\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    643\u001b[0m model_logvar \u001b[38;5;241m=\u001b[39m extract(model_logvar, t, x_t\u001b[38;5;241m.\u001b[39mshape, x_t\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 645\u001b[0m pred_x_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_x_0_from_eps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_noise\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    646\u001b[0m model_mean, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_posterior_mean_variance(\n\u001b[0;32m    647\u001b[0m         pred_x_0, x_t, t\n\u001b[0;32m    648\u001b[0m         )\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m:         model_mean,\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariance\u001b[39m\u001b[38;5;124m\"\u001b[39m:     model_var,\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_variance\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_logvar,\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_x_0\u001b[39m\u001b[38;5;124m\"\u001b[39m:     pred_x_0,\n\u001b[0;32m    654\u001b[0m     }\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\GaussianDiffusion.py:560\u001b[0m, in \u001b[0;36mGaussianDiffusionModel.predict_x_0_from_eps\u001b[1;34m(self, x_t, t, eps)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_x_0_from_eps\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_t, t, eps):\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (extract(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqrt_recip_alphas_cumprod, t, x_t\u001b[38;5;241m.\u001b[39mshape, x_t\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m x_t\n\u001b[1;32m--> 560\u001b[0m             \u001b[38;5;241m-\u001b[39m \u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt_recipm1_alphas_cumprod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "samples = diffusion.forward_backward(\n",
    "    model,\n",
    "    img.to('cuda'),\n",
    "    lab,\n",
    "    see_whole_sequence=None,\n",
    "    t_distance=1000, denoise_fn = 'gauss'\n",
    ")\n",
    "outputs = torch.cat(\n",
    "    (\n",
    "        img.to('cuda'), \n",
    "        samples,                    \n",
    "    )\n",
    ") \n",
    "plt.imshow(gridify_output(outputs, 7)[..., 0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc1caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ed42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
